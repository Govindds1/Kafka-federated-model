{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c99c43c",
   "metadata": {},
   "source": [
    "# Data Concatenation and Cleaning\n",
    "\n",
    "This notebook concatenates three CSV files (metasploitable-2.csv, Normal_data.csv, OVS.csv) from the data folder, performs basic data cleaning, and analyzes the labels in the concatenated dataset. The output is saved as concatenated_data.csv in the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9b42851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metasploitable-2.csv with shape (136743, 84)\n",
      "Loaded Normal_data.csv with shape (68424, 84)\n",
      "Loaded OVS.csv with shape (138722, 84)\n",
      "\n",
      "Concatenated DataFrame shape: (343889, 84)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "data_dir = '../data/'\n",
    "output_dir = '../output/'\n",
    "output_file = os.path.join(output_dir, 'concatenated_data.csv')\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List of CSV files\n",
    "csv_files = ['metasploitable-2.csv', 'Normal_data.csv', 'OVS.csv']\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Read and concatenate CSV files\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        if 'Label' in df.columns:\n",
    "            df['Label'] = df['Label'].str.strip()  # Remove leading/trailing whitespace\n",
    "        dfs.append(df)\n",
    "        print(f'Loaded {file} with shape {df.shape}')\n",
    "    else:\n",
    "        print(f'File {file} not found')\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "if dfs:\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(f'\\nConcatenated DataFrame shape: {concatenated_df.shape}')\n",
    "else:\n",
    "    print('No DataFrames to concatenate')\n",
    "    concatenated_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21bb112d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of concatenated DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Src IP</th>\n",
       "      <th>Src Port</th>\n",
       "      <th>Dst IP</th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.168.3.130-200.175.2.130-38694-4444-6</td>\n",
       "      <td>192.168.3.130</td>\n",
       "      <td>38694</td>\n",
       "      <td>200.175.2.130</td>\n",
       "      <td>4444</td>\n",
       "      <td>6</td>\n",
       "      <td>10/1/2020 5:02</td>\n",
       "      <td>269709</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U2R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.168.3.130-200.175.2.130-38693-4444-6</td>\n",
       "      <td>192.168.3.130</td>\n",
       "      <td>38693</td>\n",
       "      <td>200.175.2.130</td>\n",
       "      <td>4444</td>\n",
       "      <td>6</td>\n",
       "      <td>10/1/2020 5:02</td>\n",
       "      <td>268599</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U2R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.168.3.130-200.175.2.130-3632-33747-6</td>\n",
       "      <td>200.175.2.130</td>\n",
       "      <td>33747</td>\n",
       "      <td>192.168.3.130</td>\n",
       "      <td>3632</td>\n",
       "      <td>6</td>\n",
       "      <td>10/1/2020 5:02</td>\n",
       "      <td>22194</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>U2R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.168.3.130-200.175.2.130-8180-38745-6</td>\n",
       "      <td>200.175.2.130</td>\n",
       "      <td>38745</td>\n",
       "      <td>192.168.3.130</td>\n",
       "      <td>8180</td>\n",
       "      <td>6</td>\n",
       "      <td>10/1/2020 1:39</td>\n",
       "      <td>9556</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BFA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.168.3.130-200.175.2.130-8180-37217-6</td>\n",
       "      <td>200.175.2.130</td>\n",
       "      <td>37217</td>\n",
       "      <td>192.168.3.130</td>\n",
       "      <td>8180</td>\n",
       "      <td>6</td>\n",
       "      <td>10/1/2020 1:39</td>\n",
       "      <td>8782</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BFA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Flow ID         Src IP  Src Port  \\\n",
       "0  192.168.3.130-200.175.2.130-38694-4444-6  192.168.3.130     38694   \n",
       "1  192.168.3.130-200.175.2.130-38693-4444-6  192.168.3.130     38693   \n",
       "2  192.168.3.130-200.175.2.130-3632-33747-6  200.175.2.130     33747   \n",
       "3  192.168.3.130-200.175.2.130-8180-38745-6  200.175.2.130     38745   \n",
       "4  192.168.3.130-200.175.2.130-8180-37217-6  200.175.2.130     37217   \n",
       "\n",
       "          Dst IP  Dst Port  Protocol       Timestamp  Flow Duration  \\\n",
       "0  200.175.2.130      4444         6  10/1/2020 5:02         269709   \n",
       "1  200.175.2.130      4444         6  10/1/2020 5:02         268599   \n",
       "2  192.168.3.130      3632         6  10/1/2020 5:02          22194   \n",
       "3  192.168.3.130      8180         6  10/1/2020 1:39           9556   \n",
       "4  192.168.3.130      8180         6  10/1/2020 1:39           8782   \n",
       "\n",
       "   Tot Fwd Pkts  Tot Bwd Pkts  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
       "0             4             5  ...                 0          0.0         0.0   \n",
       "1             2             3  ...                 0          0.0         0.0   \n",
       "2             5             5  ...                 0          0.0         0.0   \n",
       "3             4             4  ...                 0          0.0         0.0   \n",
       "4             4             4  ...                 0          0.0         0.0   \n",
       "\n",
       "   Active Max  Active Min  Idle Mean  Idle Std  Idle Max  Idle Min  Label  \n",
       "0         0.0         0.0        0.0       0.0       0.0       0.0    U2R  \n",
       "1         0.0         0.0        0.0       0.0       0.0       0.0    U2R  \n",
       "2         0.0         0.0        0.0       0.0       0.0       0.0    U2R  \n",
       "3         0.0         0.0        0.0       0.0       0.0       0.0    BFA  \n",
       "4         0.0         0.0        0.0       0.0       0.0       0.0    BFA  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 343889 entries, 0 to 343888\n",
      "Data columns (total 84 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Flow ID            343889 non-null  object \n",
      " 1   Src IP             343889 non-null  object \n",
      " 2   Src Port           343889 non-null  int64  \n",
      " 3   Dst IP             343889 non-null  object \n",
      " 4   Dst Port           343889 non-null  int64  \n",
      " 5   Protocol           343889 non-null  int64  \n",
      " 6   Timestamp          343889 non-null  object \n",
      " 7   Flow Duration      343889 non-null  int64  \n",
      " 8   Tot Fwd Pkts       343889 non-null  int64  \n",
      " 9   Tot Bwd Pkts       343889 non-null  int64  \n",
      " 10  TotLen Fwd Pkts    343889 non-null  float64\n",
      " 11  TotLen Bwd Pkts    343889 non-null  float64\n",
      " 12  Fwd Pkt Len Max    343889 non-null  int64  \n",
      " 13  Fwd Pkt Len Min    343889 non-null  int64  \n",
      " 14  Fwd Pkt Len Mean   343889 non-null  float64\n",
      " 15  Fwd Pkt Len Std    343889 non-null  float64\n",
      " 16  Bwd Pkt Len Max    343889 non-null  int64  \n",
      " 17  Bwd Pkt Len Min    343889 non-null  int64  \n",
      " 18  Bwd Pkt Len Mean   343889 non-null  float64\n",
      " 19  Bwd Pkt Len Std    343889 non-null  float64\n",
      " 20  Flow Byts/s        343889 non-null  float64\n",
      " 21  Flow Pkts/s        343889 non-null  float64\n",
      " 22  Flow IAT Mean      343889 non-null  float64\n",
      " 23  Flow IAT Std       343889 non-null  float64\n",
      " 24  Flow IAT Max       343889 non-null  float64\n",
      " 25  Flow IAT Min       343889 non-null  float64\n",
      " 26  Fwd IAT Tot        343889 non-null  float64\n",
      " 27  Fwd IAT Mean       343889 non-null  float64\n",
      " 28  Fwd IAT Std        343889 non-null  float64\n",
      " 29  Fwd IAT Max        343889 non-null  float64\n",
      " 30  Fwd IAT Min        343889 non-null  float64\n",
      " 31  Bwd IAT Tot        343889 non-null  float64\n",
      " 32  Bwd IAT Mean       343889 non-null  float64\n",
      " 33  Bwd IAT Std        343889 non-null  float64\n",
      " 34  Bwd IAT Max        343889 non-null  float64\n",
      " 35  Bwd IAT Min        343889 non-null  float64\n",
      " 36  Fwd PSH Flags      343889 non-null  int64  \n",
      " 37  Bwd PSH Flags      343889 non-null  int64  \n",
      " 38  Fwd URG Flags      343889 non-null  int64  \n",
      " 39  Bwd URG Flags      343889 non-null  int64  \n",
      " 40  Fwd Header Len     343889 non-null  int64  \n",
      " 41  Bwd Header Len     343889 non-null  int64  \n",
      " 42  Fwd Pkts/s         343889 non-null  float64\n",
      " 43  Bwd Pkts/s         343889 non-null  float64\n",
      " 44  Pkt Len Min        343889 non-null  int64  \n",
      " 45  Pkt Len Max        343889 non-null  int64  \n",
      " 46  Pkt Len Mean       343889 non-null  float64\n",
      " 47  Pkt Len Std        343889 non-null  float64\n",
      " 48  Pkt Len Var        343889 non-null  float64\n",
      " 49  FIN Flag Cnt       343889 non-null  int64  \n",
      " 50  SYN Flag Cnt       343889 non-null  int64  \n",
      " 51  RST Flag Cnt       343889 non-null  int64  \n",
      " 52  PSH Flag Cnt       343889 non-null  int64  \n",
      " 53  ACK Flag Cnt       343889 non-null  int64  \n",
      " 54  URG Flag Cnt       343889 non-null  int64  \n",
      " 55  CWE Flag Count     343889 non-null  int64  \n",
      " 56  ECE Flag Cnt       343889 non-null  int64  \n",
      " 57  Down/Up Ratio      343889 non-null  int64  \n",
      " 58  Pkt Size Avg       343889 non-null  float64\n",
      " 59  Fwd Seg Size Avg   343889 non-null  float64\n",
      " 60  Bwd Seg Size Avg   343889 non-null  float64\n",
      " 61  Fwd Byts/b Avg     343889 non-null  int64  \n",
      " 62  Fwd Pkts/b Avg     343889 non-null  int64  \n",
      " 63  Fwd Blk Rate Avg   343889 non-null  int64  \n",
      " 64  Bwd Byts/b Avg     343889 non-null  int64  \n",
      " 65  Bwd Pkts/b Avg     343889 non-null  int64  \n",
      " 66  Bwd Blk Rate Avg   343889 non-null  int64  \n",
      " 67  Subflow Fwd Pkts   343889 non-null  int64  \n",
      " 68  Subflow Fwd Byts   343889 non-null  int64  \n",
      " 69  Subflow Bwd Pkts   343889 non-null  int64  \n",
      " 70  Subflow Bwd Byts   343889 non-null  int64  \n",
      " 71  Init Fwd Win Byts  343889 non-null  int64  \n",
      " 72  Init Bwd Win Byts  343889 non-null  int64  \n",
      " 73  Fwd Act Data Pkts  343889 non-null  int64  \n",
      " 74  Fwd Seg Size Min   343889 non-null  int64  \n",
      " 75  Active Mean        343889 non-null  float64\n",
      " 76  Active Std         343889 non-null  float64\n",
      " 77  Active Max         343889 non-null  float64\n",
      " 78  Active Min         343889 non-null  float64\n",
      " 79  Idle Mean          343889 non-null  float64\n",
      " 80  Idle Std           343889 non-null  float64\n",
      " 81  Idle Max           343889 non-null  float64\n",
      " 82  Idle Min           343889 non-null  float64\n",
      " 83  Label              343889 non-null  object \n",
      "dtypes: float64(38), int64(41), object(5)\n",
      "memory usage: 220.4+ MB\n",
      "\n",
      "Missing Values:\n",
      "Flow ID      0\n",
      "Src IP       0\n",
      "Src Port     0\n",
      "Dst IP       0\n",
      "Dst Port     0\n",
      "            ..\n",
      "Idle Mean    0\n",
      "Idle Std     0\n",
      "Idle Max     0\n",
      "Idle Min     0\n",
      "Label        0\n",
      "Length: 84, dtype: int64\n",
      "\n",
      "Duplicate Rows:\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Basic data exploration\n",
    "if not concatenated_df.empty:\n",
    "    print('\\nFirst 5 rows of concatenated DataFrame:')\n",
    "    display(concatenated_df.head())\n",
    "    \n",
    "    print('\\nDataFrame Info:')\n",
    "    concatenated_df.info()\n",
    "    \n",
    "    print('\\nMissing Values:')\n",
    "    print(concatenated_df.isnull().sum())\n",
    "    \n",
    "    print('\\nDuplicate Rows:')\n",
    "    print(concatenated_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a224fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing duplicates: (205166, 84)\n",
      "\n",
      "Missing Values After Cleaning:\n",
      "Flow ID      0\n",
      "Src IP       0\n",
      "Src Port     0\n",
      "Dst IP       0\n",
      "Dst Port     0\n",
      "            ..\n",
      "Idle Mean    0\n",
      "Idle Std     0\n",
      "Idle Max     0\n",
      "Idle Min     0\n",
      "Label        0\n",
      "Length: 84, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/np/ds9v8zlx33j30nx7p_2wlx_80000gn/T/ipykernel_4669/3126887602.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  concatenated_df[column].fillna(concatenated_df[column].mode()[0], inplace=True)\n",
      "/var/folders/np/ds9v8zlx33j30nx7p_2wlx_80000gn/T/ipykernel_4669/3126887602.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  concatenated_df[column].fillna(concatenated_df[column].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned data saved to ../output/concatenated_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Data cleaning\n",
    "if not concatenated_df.empty:\n",
    "    # Remove duplicate rows\n",
    "    concatenated_df = concatenated_df.drop_duplicates()\n",
    "    print(f'Shape after removing duplicates: {concatenated_df.shape}')\n",
    "    \n",
    "    # Handle missing values (example: fill numeric with mean, categorical with mode)\n",
    "    for column in concatenated_df.columns:\n",
    "        if concatenated_df[column].dtype in ['int64', 'float64']:\n",
    "            concatenated_df[column].fillna(concatenated_df[column].mean(), inplace=True)\n",
    "        else:\n",
    "            concatenated_df[column].fillna(concatenated_df[column].mode()[0], inplace=True)\n",
    "    \n",
    "    print('\\nMissing Values After Cleaning:')\n",
    "    print(concatenated_df.isnull().sum())\n",
    "    \n",
    "    # Save the cleaned DataFrame\n",
    "    concatenated_df.to_csv(output_file, index=False)\n",
    "    print(f'\\nCleaned data saved to {output_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cfcef0",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The concatenated and cleaned data is saved as `concatenated_data.csv` in the output folder. Proceed with applying federated learning concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b638316a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of combined data: (343889, 84)\n",
      "\n",
      "Unique labels (attack types): ['U2R', 'BFA', 'DDoS', 'DoS', 'Probe', 'Normal', 'Web-Attack', 'BOTNET']\n",
      "\n",
      "Count of each label:\n",
      "Label\n",
      "DDoS          121942\n",
      "Probe          98129\n",
      "Normal         68424\n",
      "DoS            53616\n",
      "BFA             1405\n",
      "Web-Attack       192\n",
      "BOTNET           164\n",
      "U2R               17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Label analysis\n",
    "if not concatenated_df.empty:\n",
    "    if 'Label' in concatenated_df.columns:\n",
    "        print(f'\\nShape of combined data: {concatenated_df.shape}')\n",
    "        unique_labels = concatenated_df['Label'].unique()\n",
    "        print('\\nUnique labels (attack types):', unique_labels.tolist())\n",
    "        label_counts = concatenated_df['Label'].value_counts()\n",
    "        print('\\nCount of each label:')\n",
    "        print(label_counts)\n",
    "    else:\n",
    "        print(\"\\nError: 'Label' column not found in the DataFrame. Please check column names.\")\n",
    "        print('Available columns:', concatenated_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ae3553e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inspecting raw CSV files:\n",
      "\n",
      "metasploitable-2.csv shape: (136743, 84)\n",
      "Unique labels in metasploitable-2.csv: ['U2R', 'BFA', 'DDoS', 'DoS', 'Probe']\n",
      "Label counts in metasploitable-2.csv:\n",
      "Label\n",
      "DDoS     73529\n",
      "Probe    61757\n",
      "DoS       1145\n",
      "BFA        295\n",
      "U2R         17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Normal_data.csv shape: (68424, 84)\n",
      "Unique labels in Normal_data.csv: ['Normal']\n",
      "Label counts in Normal_data.csv:\n",
      "Label\n",
      "Normal    68424\n",
      "Name: count, dtype: int64\n",
      "\n",
      "OVS.csv shape: (138722, 84)\n",
      "Unique labels in OVS.csv: ['BFA', 'DDoS ', 'DoS', 'Probe', 'Web-Attack', 'BOTNET']\n",
      "Label counts in OVS.csv:\n",
      "Label\n",
      "DoS           52471\n",
      "DDoS          48413\n",
      "Probe         36372\n",
      "BFA            1110\n",
      "Web-Attack      192\n",
      "BOTNET          164\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify raw CSV files\n",
    "print('\\nInspecting raw CSV files:')\n",
    "for file in ['metasploitable-2.csv', 'Normal_data.csv', 'OVS.csv']:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f'\\n{file} shape: {df.shape}')\n",
    "        if 'Label' in df.columns:\n",
    "            print(f'Unique labels in {file}:', df['Label'].unique().tolist())\n",
    "            print(f'Label counts in {file}:\\n{df[\"Label\"].value_counts()}')\n",
    "        else:\n",
    "            print(f\"No 'Label' column in {file}. Available columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c6064",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The concatenated and cleaned data is saved as `concatenated_data.csv` in the output folder. The label analysis above shows the distribution of attack types for metasploitable-2.csv, Normal_data.csv, and OVS.csv. If the output matches expectations, proceed with federated learning. If labels or row counts differ from expected, review the raw CSV inspection above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042be6f",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The concatenated and cleaned data is saved as `concatenated_data.csv` in the output folder. The label analysis above shows the distribution of attack types for metasploitable-2.csv, Normal_data.csv, and OVS.csv, with 'DDoS' and 'DDoS ' combined into a single label. The data is then clubbed into three files (ddos_data.csv, dos_data.csv, probe_data.csv) in the output_clubbed folder, each including Normal and specific attack types. Proceed with federated learning using these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed8b741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ddos_data.csv with shape (191771, 84) and labels ['BFA', 'DDoS', 'Normal']\n",
      "Saved dos_data.csv with shape (166745, 84) and labels ['Probe', 'Normal', 'Web-Attack']\n",
      "Saved probe_data.csv with shape (122204, 84) and labels ['DoS', 'Normal', 'BOTNET']\n"
     ]
    }
   ],
   "source": [
    "# Club data into three categories\n",
    "if not concatenated_df.empty and 'Label' in concatenated_df.columns:\n",
    "    # Define output directory for clubbed data\n",
    "    clubbed_output_dir = '../output_clubbed/'\n",
    "    os.makedirs(clubbed_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Define label groups\n",
    "    ddos_labels = ['DDoS', 'Normal', 'BFA']\n",
    "    dos_labels = ['Probe', 'Normal', 'Web-Attack']\n",
    "    probe_labels = ['Normal', 'DoS', 'BOTNET']\n",
    "    \n",
    "    # Create and save clubbed datasets\n",
    "    ddos_data = concatenated_df[concatenated_df['Label'].isin(ddos_labels)]\n",
    "    ddos_data.to_csv(os.path.join(clubbed_output_dir, 'ddos_data.csv'), index=False)\n",
    "    print(f'Saved ddos_data.csv with shape {ddos_data.shape} and labels {ddos_data[\"Label\"].unique().tolist()}')\n",
    "    \n",
    "    dos_data = concatenated_df[concatenated_df['Label'].isin(dos_labels)]\n",
    "    dos_data.to_csv(os.path.join(clubbed_output_dir, 'dos_data.csv'), index=False)\n",
    "    print(f'Saved dos_data.csv with shape {dos_data.shape} and labels {dos_data[\"Label\"].unique().tolist()}')\n",
    "    \n",
    "    probe_data = concatenated_df[concatenated_df['Label'].isin(probe_labels)]\n",
    "    probe_data.to_csv(os.path.join(clubbed_output_dir, 'probe_data.csv'), index=False)\n",
    "    print(f'Saved probe_data.csv with shape {probe_data.shape} and labels {probe_data[\"Label\"].unique().tolist()}')\n",
    "else:\n",
    "    print('Error: concatenated_df is empty or Label column not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2b792b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ddos_data.csv shape: (191771, 84)\n",
      "Labels: ['BFA', 'DDoS', 'Normal']\n",
      "\n",
      "dos_data.csv shape: (166745, 84)\n",
      "Labels: ['Probe', 'Normal', 'Web-Attack']\n",
      "\n",
      "probe_data.csv shape: (122204, 84)\n",
      "Labels: ['DoS', 'Normal', 'BOTNET']\n"
     ]
    }
   ],
   "source": [
    "for file in ['ddos_data.csv', 'dos_data.csv', 'probe_data.csv']:\n",
    "    df = pd.read_csv(os.path.join(clubbed_output_dir, file))\n",
    "    print(f'\\n{file} shape: {df.shape}')\n",
    "    print(f'Labels: {df[\"Label\"].unique().tolist()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
